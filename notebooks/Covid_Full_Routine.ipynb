{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from io import StringIO\n",
    "from IPython import get_ipython\n",
    "import datetime\n",
    "from shutil import copyfile\n",
    "\n",
    "\n",
    "\n",
    "class IpyExit(SystemExit):\n",
    "    \"\"\"Exit Exception for IPython.\n",
    "\n",
    "    Exception temporarily redirects stderr to buffer.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        print(\"exiting\")\n",
    "        sys.stderr = StringIO()\n",
    "\n",
    "    def __del__(self):\n",
    "        sys.stderr.close()\n",
    "        sys.stderr = sys.__stderr__  # restore from backup\n",
    "\n",
    "def ipy_exit():\n",
    "    raise IpyExit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------\n",
    "## Prepare Source, Data and Directories\n",
    "- set input/output directories and user settings\n",
    "- download source from github\n",
    "- replace data directory with precomputed one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **REQUIREMENTS:**\n",
    "   - you have joined the project `covid19dynstat`\n",
    "   - you have created the directory `$PROJECT_covid19dynstat/$USER`\n",
    "   - you have copied/linked a `data` directory to `$PROJECT_covid19dynstat/$USER/data`\n",
    "       - will replace `data` from git repository\n",
    "       - MUST include `counties/counties.pkl` (explicitly for JURECA, not from git repo!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-10\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "# fixed parameters\n",
    "user_email = \"leffenberger@uos.de\"\n",
    "cmpprj_name = \"covid19dynstat\" # do not change (used in slurm-file)\n",
    "\n",
    "# run:\n",
    "run_name = \"BSTIM-Covid19_Window_Final\"\n",
    "\n",
    "# source: clone only first time with 'run_name'\n",
    "git_repo = \"https://github.com/neuroinfo-os/BSTIM-Covid19.git\"\n",
    "git_branch = \"3WeekPred\"\n",
    "\n",
    "# csv: update if missing or requested\n",
    "csv_update = True\n",
    "\n",
    "# run slurm dependency chain\n",
    "slurm_chain = False\n",
    "\n",
    "today_date = datetime.date(2020,7,6) # year, month, day\n",
    "sample_date = today_date - datetime.timedelta(days=26)\n",
    "print(sample_date)\n",
    "start_date = datetime.date(2020,1,28)\n",
    "sample_date_id = (sample_date - start_date).days\n",
    "\n",
    "# simulation: sample_ia\n",
    "submit_job_ia   = True\n",
    "job_ia_nodes        = 25 # 25\n",
    "job_ia_taskspernode = 4 # 4\n",
    "job_ia_runtime      = '24:00:00' # '24:00:00'\n",
    "\n",
    "# simulation: sample_posterior\n",
    "submit_job_post   = True\n",
    "job_post_nodes        = 42 # 42\n",
    "job_post_taskspernode = 6 # 6\n",
    "job_post_runtime      = '8:00:00' # '24:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n"
     ]
    }
   ],
   "source": [
    "print(sample_date_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set input/output directories and user settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_proj_dir =  /p/project/covid19dynstat/effenberger2\n",
      "slurm_out_dir =  /p/project/covid19dynstat/effenberger2/run\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# check users project directory\n",
    "# (do NOT change as it is used in SLURM-jobscript, too)\n",
    "user_proj_dir = os.path.join(os.getenv('PROJECT_'+cmpprj_name), os.getenv('USER'))\n",
    "if not os.path.isdir(user_proj_dir):\n",
    "    print(\"ERROR: project directory has no directory of the current user.\")\n",
    "    print(\"       please create \", user_proj_dir)\n",
    "    raise IpyExit\n",
    "else:\n",
    "    print(\"user_proj_dir = \", user_proj_dir)\n",
    "    \n",
    "# check for SLURM output directory\n",
    "# (do not change as it is set in SLURM-jobscript, too)\n",
    "slurm_out_dir = os.path.join(user_proj_dir, 'run')\n",
    "if not os.path.isdir(user_proj_dir):\n",
    "    print(\"ERROR: SLURM output directory does not exist.\")\n",
    "    print(\"       please create \", slurm_out_dir)\n",
    "    raise IpyExit\n",
    "else:\n",
    "    print(\"slurm_out_dir = \", slurm_out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download source "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_dir =  /p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final\n",
      "source_data_dir =  /p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/data\n",
      "NO cloning of git repository\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from git import Repo\n",
    "\n",
    "# auto-generate run_name if empty\n",
    "if not run_name:\n",
    "    run_name = datetime.now().strftime(\"BSTIM-Covid19_%Y-%m-%d_%H-%M-%S_\" + git_branch)\n",
    "\n",
    "# set source_dir\n",
    "source_dir = os.path.join(user_proj_dir, run_name)\n",
    "print(\"source_dir = \", source_dir)\n",
    "\n",
    "# set source_data_dir\n",
    "source_data_dir = os.path.join(source_dir, 'data')\n",
    "print(\"source_data_dir = \", source_data_dir)\n",
    "\n",
    "# clone source if required\n",
    "if not os.path.exists(source_dir):\n",
    "    print(\"cloning git repository\")\n",
    "\n",
    "    if not git_branch:\n",
    "        git_branch = 'master'\n",
    "    print(\"git_branch = \", git_branch)\n",
    "\n",
    "    if not git_repo:\n",
    "        git_repo = 'https://github.com/neuroinfo-os/BSTIM-Covid19.git'\n",
    "    print(\"git_repo = \", git_repo)\n",
    "\n",
    "    repo = Repo.clone_from(git_repo, source_dir, branch=git_branch)\n",
    "    #repo.heads['tag-name'].checkout() # checkout a certain tag\n",
    "\n",
    "    # rename data dir if from clean checkout\n",
    "    if os.path.exists(source_data_dir):\n",
    "        os.rename(source_data_dir,  os.path.join(source_dir,'data_git'))\n",
    "else:\n",
    "    print(\"NO cloning of git repository\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace data directory with precomputed one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO replacing of data directory\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# copy new data dir with precomputed pickel file\n",
    "# if data directory does not exist\n",
    "if not os.path.exists(source_data_dir):\n",
    "    print(\"replacing data directory\")\n",
    "    user_data_dir = os.path.join(user_proj_dir, 'data')\n",
    "    if os.path.exists(user_data_dir) and os.path.isdir(user_data_dir):\n",
    "        shutil.copytree(user_data_dir, source_data_dir)\n",
    "    else:\n",
    "        print(\"ERROR: user data directory does not exists or is no directory.\")\n",
    "        raise IpyExit\n",
    "else:\n",
    "    print(\"NO replacing of data directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------\n",
    "## Get COVID-19 data from RKI\n",
    "Covid-19 data is provided by the [Robert Koch Institute][4] via the publically accessiable [this](https://npgeo-corona-npgeo-de.hub.arcgis.com/datasets/dd4580c810204019a7b8eb3e0b329dd6_0/data?orderBy=Meldedatum) link.  \n",
    "We download the CSV table and store it in `./data/raw/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download COVID-19 CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_csv_fpath =  /p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/data/raw/covid19.csv\n",
      "download COVID-19 data\n",
      "raw_csv_url =  https://opendata.arcgis.com/datasets/dd4580c810204019a7b8eb3e0b329dd6_0.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "raw_csv_fpath = os.path.join(source_data_dir, 'raw', \"covid19.csv\")\n",
    "print(\"raw_csv_fpath = \", raw_csv_fpath)\n",
    "\n",
    "# download csv data if asked for\n",
    "if not os.path.exists(raw_csv_fpath) or csv_update:\n",
    "    print('download COVID-19 data')\n",
    "\n",
    "    raw_csv_url = 'https://opendata.arcgis.com/datasets/dd4580c810204019a7b8eb3e0b329dd6_0.csv'\n",
    "    raw_csv_red = requests.get(raw_csv_url, allow_redirects=True)\n",
    "    print(\"raw_csv_url = \", raw_csv_url)\n",
    "\n",
    "    open(raw_csv_fpath, 'wb').write(raw_csv_red.content)\n",
    "else:\n",
    "    print(\"NO download of COVID-19 data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess COVID-19 CSV\n",
    "The downloadable CSV table can be found in `./data/raw/` and is preprocessed to fit the BSTI Model implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_csv_fpath =  /p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/data/raw/../diseases/covid19.csv\n",
      "preprocessing csv 2020-01-28 00:00:00\n",
      "............................................................................................................................................................................................................................................................................................................................................................................................................................"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/p/project/covid19dynstat/.local/share/venvs/covid19dynstat_v01/lib/python3.6/site-packages/ipykernel/__main__.py:51: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " finished\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import argparse\n",
    "import re\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "def preprocess_covid19_table(input_csv, output_csv):\n",
    "    \"\"\"Converts Covid-19 Data.Tabels provided by the RKI to a simpler format to fit the model\"\"\"\n",
    "\n",
    "    counties = OrderedDict()\n",
    "    with open(\"/p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/data/raw/germany_county_shapes.json\", \"r\") as data_file:\n",
    "        shape_data = json.load(data_file)\n",
    "\n",
    "    for idx, val in enumerate(shape_data[\"features\"]):\n",
    "        id_current = val[\"properties\"][\"RKI_ID\"]\n",
    "        name_current = val[\"properties\"][\"RKI_NameDE\"]\n",
    "\n",
    "        counties[name_current] = id_current\n",
    "\n",
    "    covid19_data = pd.read_csv(input_csv, sep=',')\n",
    "    #print(covid19_data)\n",
    "    # this complicated procedure removes timezone information.\n",
    "    regex = re.compile(r\"([0-9]+)/([0-9]+)/([0-9]+).*\")\n",
    "    start_year, start_month, start_day = regex.search(\n",
    "        covid19_data['Meldedatum'].min()).groups()\n",
    "    end_year, end_month, end_day = regex.search(\n",
    "        covid19_data['Meldedatum'].max()).groups()\n",
    "    start_date = pd.Timestamp(\n",
    "        int(start_year), int(start_month), int(start_day))\n",
    "    end_date = pd.Timestamp(int(end_year), int(end_month), int(end_day))\n",
    "\n",
    "    dates = [day for day in pd.date_range(start_date, end_date)]\n",
    "    print(start_date)\n",
    "    df = pd.DataFrame(index=dates)\n",
    "    for county_name in counties:\n",
    "        print('.',end='')\n",
    "        series = np.zeros(len(df), dtype=np.int32)\n",
    "        lk_data = covid19_data[covid19_data['Landkreis'] == county_name]\n",
    "        for (d_id, day) in enumerate(dates):\n",
    "            day_string = \"{:04d}/{:02d}/{:02d} 00:00:00\".format(day.year, day.month, day.day)\n",
    "            cases = np.sum(lk_data[lk_data['Meldedatum']\n",
    "                                   == day_string]['AnzahlFall'])\n",
    "            if cases > 0:\n",
    "                series[d_id] = cases\n",
    "        df.insert(len(df.columns), counties[county_name], series)\n",
    "    df_total = df.sum(axis=1)\n",
    "    df_total.to_csv(\"/p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/data/raw/../diseases/covid19_total.csv\")\n",
    "    df.to_csv(output_csv, sep=\",\")\n",
    "\n",
    "data_csv_fpath = os.path.join(os.path.dirname(raw_csv_fpath), \"..\", \"diseases\", os.path.basename(raw_csv_fpath))\n",
    "print(\"data_csv_fpath = \", data_csv_fpath)\n",
    "\n",
    "if not os.path.exists(data_csv_fpath) or csv_update:\n",
    "    print(\"preprocessing csv \", end='')\n",
    "    preprocess_covid19_table(raw_csv_fpath, data_csv_fpath)\n",
    "    print(\" finished\")\n",
    "else:\n",
    "    print(\"NO preprocessing csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------\n",
    "## Simulation 1: Sample Interaction Effects (100x)\n",
    "\n",
    "SAMPLE NEW IA EFFECTS FOR WINDOW (CURRENTLY 3 WEEKS)\n",
    "\n",
    "`sample_ia_effects_window.py` reads  \n",
    "- ../data/counties/counties.pkl\n",
    "- ../data/diseases/{covid19}.csv\n",
    "\n",
    "and outputs:\n",
    "- ../data/ia_effect_samples/${sample_date}/{}_{}.pkl\n",
    "\n",
    "sample_ia_effects.py is called 100x by SLURM (=farming) and calculates the same thing with different random numbers:  \n",
    "- gridjob_sample_ia.slurm \n",
    "  - `#SBATCH --array=1-100:4`\n",
    "- gridjob_sample_ia.slurm.sh\n",
    "  - `THEANO_FLAGS=\"base_compiledir=${TASK_DIR}/,floatX=float32,device=cpu,openmp=True,mode=FAST_RUN,warn_float64=warn\" OMP_NUM_THREADS=8  python3 sample_ia_effects_window.py > ${TASK_DIR}/log.txt`\n",
    "- sample_ia_effects_window.py\n",
    "  - ```nums_sample = range(100)\n",
    "GID = int(os.environ[\"SGE_TASK_ID\"])\n",
    "num_sample = nums_sample[GID - 1]\n",
    "filename = \"../data/ia_effect_samples/${sample_date}/{}_{}.pkl\".format(disease, num_sample)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slurm_jobfile_ia =  /p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/src/gridjob_sample_ia_window.slurm\n",
      "slurm_shfile_ia =  /p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/src/gridjob_sample_ia_window.slurm.sh\n",
      "file_counties =  /p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/data/counties/counties.pkl\n",
      "file_covid19 =  /p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/data/diseases/covid19.csv\n",
      "dir_iaeffect =  /p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/data/ia_effect_samples\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# slurm jobfile\n",
    "slurm_jobfile_ia = os.path.join(source_dir, 'src', \"gridjob_sample_ia_window.slurm\")\n",
    "if not os.path.exists(slurm_jobfile_ia):\n",
    "    print(\"ERROR: original SLURM job file does not exist\")\n",
    "    print(\"       please check for \", slurm_jobfile_ia)\n",
    "    raise IpyExit\n",
    "print(\"slurm_jobfile_ia = \", slurm_jobfile_ia)\n",
    "    \n",
    "slurm_shfile_ia_original = os.path.join(source_dir, 'src', \"gridjob_sample_ia_window.slurm.sh\")\n",
    "if not os.path.exists(slurm_shfile_ia_original):\n",
    "    print(\"ERROR: original SLURM sh file does not exist\")\n",
    "    print(\"       please check for \", slurm_shfile_ia_original)\n",
    "    raise IpyExit\n",
    "print(\"slurm_shfile_ia = \", slurm_shfile_ia_original)\n",
    "\n",
    "\n",
    "slurm_shfile_ia = os.path.join(source_dir, 'src', \"gridjob_sample_ia_window_{}.slurm.sh\".format(sample_date_id))\n",
    "copyfile(slurm_shfile_ia_original, slurm_shfile_ia)\n",
    "    \n",
    "# check is shell-script has executable bit\n",
    "if not os.access(slurm_shfile_ia, os.X_OK):\n",
    "    with open(slurm_shfile_ia, \"r\") as fd:\n",
    "        os.chmod(fd.fileno(), 0o755)\n",
    "\n",
    "if submit_job_ia:\n",
    "    \n",
    "    # check required input\n",
    "    file_counties = os.path.join(source_data_dir, 'counties', 'counties.pkl')\n",
    "    if not os.path.isfile(file_counties):\n",
    "        print(\"ERROR: file data/counties.pkl is missing\")\n",
    "        raise IpyExit\n",
    "    else:\n",
    "        print(\"file_counties = \", file_counties)\n",
    "        \n",
    "    file_covid19 = os.path.join(source_data_dir, 'diseases', 'covid19.csv')\n",
    "    if not os.path.isfile(file_covid19):\n",
    "        print(\"ERROR: file data/covid19.csv is missing\")\n",
    "        raise IpyExit\n",
    "    print(\"file_covid19 = \", file_covid19)\n",
    "    \n",
    "    # check output directory\n",
    "    dir_iaeffect = os.path.join(source_data_dir, 'ia_effect_samples')\n",
    "    if not os.path.exists(dir_iaeffect):\n",
    "        os.mkdir(dir_iaeffect)    \n",
    "    if not os.path.isdir(dir_iaeffect):\n",
    "        print(\"ERROR: \" + dir_iaeffect + \" not a directroy\")\n",
    "        raise IpyExit\n",
    "    #if os.listdir(dir_iaeffect):\n",
    "    #    print(\"ERROR: directory \" + dir_iaeffect + \" not empty\")\n",
    "    #    raise IpyExit\n",
    "    print(\"dir_iaeffect = \", dir_iaeffect)\n",
    "\n",
    "else:\n",
    "    print(\"NO checking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/src\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.join(source_dir,'src'))\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileinput\n",
    "fileinput.close()\n",
    "\n",
    "def prepare_jobfile_ia(slurm_jobfile_ia):\n",
    "    \n",
    "    # replace lines with user-info\n",
    "    finput = fileinput.input(slurm_jobfile_ia, inplace=1)\n",
    "    try:\n",
    "        for line in finput:\n",
    "            line = \"#SBATCH --job-name={}_IA_ROUT\\n\".format(sample_date_id) if \"#SBATCH --job-name=\" in line else line\n",
    "            line = \"#SBATCH --array=1-{}:{}\\n\".format(job_ia_nodes * job_ia_taskspernode, job_ia_taskspernode) if \"#SBATCH --array=\" in line else line\n",
    "            line = \"#SBATCH --ntasks-per-node={}\\n\".format(job_ia_taskspernode) if \"#SBATCH --ntasks-per-node=\" in line else line\n",
    "            line = \"#SBATCH --nodes=1\\n\"                          if \"#SBATCH --nodes=\"       in line else line\n",
    "            line = \"#SBATCH --time={}\\n\".format(job_ia_runtime) if \"#SBATCH --time=\"        in line else line\n",
    "            line = \"#SBATCH --export=DATE_ID={}\\n\".format(sample_date_id) if \"#SBATCH --export=DATE_ID\" in line else line\n",
    "            line = \"#SBATCH --mail-type=ALL\\n\"                  if \"# #SBATCH --mail-type=\" in line else line\n",
    "            line = \"#SBATCH --mail-user=\" + user_email + '\\n'   if \"# #SBATCH --mail-user=\" in line else line\n",
    "            line = \"# mkdir -p ${PROJECT}/${USER}/runs/\\n\" if \"mkdir -p ${PROJECT}/${USER}/runs/\" in line else line\n",
    "            line = \"srun --exclusive -n ${{SLURM_NTASKS}} gridjob_sample_ia_window_{}.slurm.sh\".format(sample_date_id) if \"srun\" in line else line\n",
    "            print(line, end='')\n",
    "        finput.close()\n",
    "    except:\n",
    "        print(\"ERROR: could not prepare slurm job file\")\n",
    "        raise IpyExit\n",
    "    #finput.close()\n",
    "\n",
    "if submit_job_ia:\n",
    "    prepare_jobfile_ia(slurm_jobfile_ia)\n",
    "else:\n",
    "    print(\"NO submit of slurm ia job\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileinput\n",
    "\n",
    "def prepare_shfile_ia(slurm_shfile_ia):\n",
    "    \n",
    "    # replace lines with user-info\n",
    "    finput = fileinput.input(slurm_shfile_ia, inplace=1)\n",
    "    try:\n",
    "        for line in finput:\n",
    "            line = \"DAT_ID={}\\n\".format(sample_date_id) if \"DAT_ID=\" in line else line\n",
    "            print(line, end='')\n",
    "    except:\n",
    "        print(\"ERROR: could not prepare slurm job file\")\n",
    "        raise IpyExit\n",
    "    finput.close()\n",
    "\n",
    "if submit_job_ia:\n",
    "    prepare_shfile_ia(slurm_shfile_ia)\n",
    "else:\n",
    "    print(\"NO submit of slurm ia job\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from subprocess import (Popen, PIPE)\n",
    "\n",
    "def submit_job(slurm_jobfile, submit_dir, sbatch_addargs=''):\n",
    "    print(\"submitting slurm job\")\n",
    "    \n",
    "    # build sbatch command\n",
    "    sbatch_args = sbatch_addargs + \" \" + slurm_jobfile\n",
    "    sbatch_cmd = ['sbatch'] + sbatch_args.split()\n",
    "    print(\"sbatch_cmd = \", sbatch_cmd)\n",
    "\n",
    "    # submit SLURM job\n",
    "    process = Popen(sbatch_cmd, stdin=PIPE, stdout=PIPE, stderr=PIPE, cwd=submit_dir)\n",
    "    \n",
    "    # block until finished and output stdout, stderr\n",
    "    stdout, stderr = process.communicate() \n",
    "    sbatch_out = stdout.decode(\"utf-8\")\n",
    "    sbatch_err = stderr.decode(\"utf-8\")\n",
    "    \n",
    "    print(\"---- stdout ----\")        \n",
    "    print(sbatch_out)\n",
    "    print(\"---- stderr ----\")\n",
    "    print(sbatch_err)\n",
    "        \n",
    "    if process.returncode != 0:\n",
    "        raise IpyExit\n",
    "    \n",
    "    # get SLURM job id\n",
    "    slurm_jobid = ''\n",
    "    if sbatch_out:\n",
    "        slurm_jobid = sbatch_out.split()[-1]\n",
    "    print(\"slurm_jobid = \", slurm_jobid)\n",
    "\n",
    "    # save SLURM job id to file\n",
    "    if slurm_jobid:\n",
    "        with open(os.path.join(submit_dir, slurm_jobfile + \".sbatchout\"), \"w\") as ofile:\n",
    "            print(\"jobid: {}\".format(slurm_jobid), file=ofile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit_dir_ia =  /p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/src\n",
      "submitting slurm job\n",
      "sbatch_cmd =  ['sbatch', '-vv', '/p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/src/gridjob_sample_ia_window.slurm']\n",
      "---- stdout ----\n",
      "Submitted batch job 8409333\n",
      "\n",
      "---- stderr ----\n",
      "sbatch: defined options\n",
      "sbatch: -------------------- --------------------\n",
      "sbatch: account             : covid19dynstat\n",
      "sbatch: array               : 1-100:4\n",
      "sbatch: job-name            : 134_IA_ROUT\n",
      "sbatch: licenses            : home@just,project@just,scratch@just\n",
      "sbatch: nodes               : 1\n",
      "sbatch: ntasks-per-node     : 4\n",
      "sbatch: partition           : batch\n",
      "sbatch: verbose             : 2\n",
      "sbatch: -------------------- --------------------\n",
      "sbatch: end of defined options\n",
      "sbatch: debug:  propagating RLIMIT_CORE=0\n",
      "sbatch: debug:  propagating SLURM_PRIO_PROCESS=0\n",
      "sbatch: debug:  propagating UMASK=0022\n",
      "sbatch: debug:  Munge authentication plugin loaded\n",
      "sbatch: Cray/Aries node selection plugin loaded\n",
      "\n",
      "slurm_jobid =  8409333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "submit_dir_ia = os.path.join(source_dir, 'src')\n",
    "print(\"submit_dir_ia = \", submit_dir_ia)\n",
    "\n",
    "if submit_job_ia:\n",
    "    submit_job(slurm_jobfile_ia, submit_dir_ia, '-vv')\n",
    "    \n",
    "    # better wait for a few seconds to ensure slurm has processed the new job internally\n",
    "    # this ensures, that squeue will show at least some information\n",
    "    time.sleep(5)\n",
    "else:\n",
    "    print(\"NO submit of slurm ia job\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slurm_jobid =  8409333\n",
      "squeue_cmd =  ['squeue', '-l', '-u', 'effenberger2', '-j', '8409333']\n",
      "Mon Jul 20 11:02:52 2020\n",
      "             JOBID PARTITION     NAME     USER    STATE       TIME TIME_LIMI  NODES NODELIST(REASON)\n",
      "  8409333_[1-97:4]     batch 134_IA_R effenber  PENDING       0:00   1:00:00      1 (Priority)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from subprocess import (Popen, PIPE)\n",
    "\n",
    "def status_job(slurm_jobid):\n",
    "                  \n",
    "    # build squeue command\n",
    "    squeue_args = ' -l -u ' + os.getenv('USER') + ' -j ' + slurm_jobid\n",
    "    squeue_cmd = ['squeue'] + squeue_args.split()\n",
    "    print(\"squeue_cmd = \", squeue_cmd)\n",
    "\n",
    "    # show status\n",
    "    squeue_out = ''\n",
    "    process = Popen(squeue_cmd, stdin=PIPE, stdout=PIPE, stderr=PIPE)\n",
    "    stdout, stderr = process.communicate()\n",
    "    if stderr:\n",
    "        print(stdout.decode(\"utf-8\"))\n",
    "        print(stderr.decode(\"utf-8\"))\n",
    "        #raise IpyExit\n",
    "    return stdout.decode(\"utf-8\")\n",
    "\n",
    "def get_slurm_jobid(sbatchout_file):\n",
    "\n",
    "    # get slurm job id from file\n",
    "    if os.path.exists(sbatchout_file):\n",
    "        with open(sbatchout_file) as ifile:\n",
    "            for line in ifile:\n",
    "                if 'jobid:' in line:\n",
    "                    slurm_jobid = line.split()[-1]\n",
    "                    print(\"slurm_jobid = \", slurm_jobid)\n",
    "                    return slurm_jobid\n",
    "    else:\n",
    "        print(\"ERROR: not found \" + sbatchout_file)\n",
    "\n",
    "# get job id\n",
    "submit_dir_ia = os.path.join(source_dir, 'src')\n",
    "sbatchout_file_ia = os.path.join(submit_dir_ia, slurm_jobfile_ia + \".sbatchout\")\n",
    "slurm_jobid_ia = get_slurm_jobid(sbatchout_file_ia)\n",
    "\n",
    "\n",
    "\n",
    "# call 'squeue'\n",
    "if submit_job_ia and slurm_jobid_ia:            \n",
    "    squeue_out_ia = status_job(slurm_jobid_ia)\n",
    "    \n",
    "    print(squeue_out_ia)\n",
    "    \n",
    "else:\n",
    "    print(\"NO submit of slurm ia job\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------\n",
    "## Simulation 2: Sample Posterior per Window\n",
    "`sample_window.py` reads  \n",
    "- ./data/counties/counties.pkl\n",
    "- ./data/ia_effect_samples/${sample_date}/covid19_{}.pkl\n",
    "\n",
    "\n",
    "and outputs:\n",
    "- ../data/mcmc_samples_backup/\n",
    "\n",
    "sample_window.py is called\n",
    "- gridjob_sample_posterior.slurm \n",
    "  - `#SBATCH --array=1'\n",
    "- gridjob_sample_posterior.slurm.sh\n",
    "  - `THEANO_FLAGS=\"base_compiledir=${TASK_DIR}/,floatX=float32,device=cpu,openmp=True,mode=FAST_RUN,warn_float64=warn\" python3 sample_window.py > ${TASK_DIR}/log.txt`\n",
    "- sample_window.py\n",
    "\n",
    "```\n",
    "filename_params = \"../data/mcmc_samples_backup/parameters_{}_{}\".format(disease, sample_date_id)\n",
    "filename_pred = \"../data/mcmc_samples_backup/predictions_{}_{}.pkl\".format(disease, sample_date_id)\n",
    "filename_pred_trend = \"../data/mcmc_samples_backup/predictions_trend_{}_{}.pkl\".format(disease, sample_date_id)\n",
    "filename_model = \"../data/mcmc_samples_backup/model_{}_{}.pkl\".format(disease, sample_date_id)```.ipynb_checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slurm_jobfile_post =  /p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/src/gridjob_sample_window_posterior.slurm\n",
      "slurm_shfile_post =  /p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/src/gridjob_sample_window_posterior_134.slurm.sh\n",
      "file_counties =  /p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/data/counties/counties.pkl\n",
      "file_iaeffect = /p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/data/ia_effect_samples/covid19_{}.pkl\n",
      "dir_mcmcsamples =  /p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/data/mcmc_samples_backup\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# check for SLURM job file\n",
    "slurm_jobfile_post = os.path.join(source_dir, 'src', \"gridjob_sample_window_posterior.slurm\")\n",
    "if not os.path.exists(slurm_jobfile_post):\n",
    "    print(\"ERROR: original SLURM job file does not exist\")\n",
    "    print(\"       please check for \", slurm_jobfile_post)\n",
    "    raise IpyExit\n",
    "else:\n",
    "    print(\"slurm_jobfile_post = \", slurm_jobfile_post)\n",
    "\n",
    "slurm_shfile_post_original = os.path.join(source_dir, 'src', \"gridjob_sample_window_posterior.slurm.sh\")\n",
    "\n",
    "slurm_shfile_post = os.path.join(source_dir, 'src', \"gridjob_sample_window_posterior_{}.slurm.sh\".format(sample_date_id))\n",
    "copyfile(slurm_shfile_post_original, slurm_shfile_post)\n",
    "\n",
    "if not os.path.exists(slurm_shfile_post):\n",
    "    print(\"ERROR: original SLURM sh file does not exist\")\n",
    "    print(\"       please check for \", slurm_shfile_post)\n",
    "    raise IpyExit\n",
    "print(\"slurm_shfile_post = \", slurm_shfile_post)\n",
    "    \n",
    "# check is shell-script has executable bit\n",
    "if not os.access(slurm_shfile_post, os.X_OK):\n",
    "    with open(slurm_shfile_post, \"r\") as fd:\n",
    "        os.fchmod(fd.fileno(), 0o755)\n",
    "\n",
    "if submit_job_post:\n",
    "    \n",
    "    # check required input\n",
    "    file_counties = os.path.join(source_data_dir, 'counties', 'counties.pkl')\n",
    "    if not os.path.isfile(file_counties):\n",
    "        print(\"ERROR: file data/counties.pkl is missing\")\n",
    "        raise IpyExit\n",
    "    else:\n",
    "        print(\"file_counties = \", file_counties)\n",
    "\n",
    "    if not slurm_chain:\n",
    "        # check output of sample_ia (only if we slurm dependencies)\n",
    "        dir_iaeffect = os.path.join(source_data_dir, 'ia_effect_samples')\n",
    "        for i in range(100):\n",
    "            file_iaeffect = os.path.join(dir_iaeffect, \"covid19_{}.pkl\".format(i))\n",
    "            if not os.path.isfile(file_iaeffect):\n",
    "                print(\"ERROR: file \" + file_iaeffect + \"  is missing\")\n",
    "                raise IpyExit\n",
    "        print(\"file_iaeffect = \" + dir_iaeffect + \"/covid19_{}.pkl\")\n",
    "    \n",
    "    # check output directory\n",
    "    dir_mcmcsamples = os.path.join(source_data_dir, 'mcmc_samples_backup')\n",
    "    if not os.path.exists(dir_mcmcsamples):\n",
    "        os.mkdir(dir_mcmcsamples)\n",
    "    if not os.path.isdir(dir_mcmcsamples):\n",
    "        print(\"ERROR: \" + dir_mcmcsamples + \" not a directory\")\n",
    "        raise IpyExit\n",
    "        \n",
    "    #if len(os.listdir(dir_mcmcsamples)) > 1:\n",
    "    #    print(\"ERROR: directory \" + dir_mcmcsamples + \" not empty\")\n",
    "    #    raise IpyExit\n",
    "    print(\"dir_mcmcsamples = \", dir_mcmcsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileinput.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare SLURM job file (sample_posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileinput\n",
    "\n",
    "IA_DONE = False\n",
    "\n",
    "def prepare_jobfile_post(slurm_jobfile_post):\n",
    "    \n",
    "    # replace lines with user-info\n",
    "    finput = fileinput.input(slurm_jobfile_post, inplace=1)\n",
    "    try:\n",
    "        for line in finput:\n",
    "            line = \"#SBATCH --job-name={}_POST_ROUT\\n\".format(sample_date_id) if \"#SBATCH --job-name=\" in line else line\n",
    "            #line = \"#SBATCH --array=1-{}\\n\".format(120) if \"#SBATCH --array=\" in line else line\n",
    "            line = \"#SBATCH --ntasks-per-node={}\\n\".format(1) if \"#SBATCH --ntasks-per-node=\" in line else line\n",
    "            line = \"#SBATCH --nodes=1\\n\"                          if \"#SBATCH --nodes=\"       in line else line\n",
    "            line = \"#SBATCH --time={}\\n\".format(job_post_runtime) if \"#SBATCH --time=\"        in line else line\n",
    "            line = \"#SBATCH --mail-type=ALL\\n\"                    if \"# #SBATCH --mail-type=\" in line else line\n",
    "            line = \"#SBATCH --mail-user=\" + user_email + '\\n'     if \"# #SBATCH --mail-user=\" in line else line\n",
    "            line = \"# mkdir -p ${PROJECT}/${USER}/runs/\\n\" if \"mkdir -p ${PROJECT}/${USER}/runs/\" in line else line\n",
    "            if IA_DONE:\n",
    "                line = \"##SBATCH --dependency=afterany:\\n\" if \"#SBATCH --dependency\" in line else line\n",
    "            else:\n",
    "                line = \"#SBATCH --dependency=afterany:{}\\n\".format(slurm_jobid_ia) if \"#SBATCH --dependency\" in line else line\n",
    "            line = \"srun --exclusive -n ${{SLURM_NTASKS}} gridjob_sample_window_posterior_{}.slurm.sh\\n\".format(sample_date_id) if \"srun\" in line else line\n",
    "            print(line, end='')\n",
    "    except:\n",
    "        print(\"ERROR: could not prepare slurm job file\")\n",
    "        raise IpyExit\n",
    "    finput.close()\n",
    "\n",
    "if submit_job_post:\n",
    "    prepare_jobfile_post(slurm_jobfile_post)\n",
    "else:\n",
    "    print(\"NO submit of slurm ia job\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_shfile_post(slurm_shfile_post):\n",
    "    \n",
    "    # replace lines with user-info\n",
    "    finput = fileinput.input(slurm_shfile_post, inplace=1)\n",
    "    try:\n",
    "        for line in finput:\n",
    "            line = \"DAT_ID={}\\n\".format(sample_date_id) if \"DAT_ID=\" in line else line\n",
    "            print(line, end='')\n",
    "    except:\n",
    "        print(\"ERROR: could not prepare slurm job file\")\n",
    "        raise IpyExit\n",
    "    finput.close()\n",
    "\n",
    "if submit_job_ia:\n",
    "    prepare_shfile_post(slurm_shfile_post)\n",
    "else:\n",
    "    print(\"NO submit of slurm ia job\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit SLURM job (sample_posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit_dir_post =  /p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/src\n",
      "submitting slurm job\n",
      "sbatch_cmd =  ['sbatch', '-vv', '/p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/src/gridjob_sample_window_posterior.slurm']\n",
      "---- stdout ----\n",
      "Submitted batch job 8409343\n",
      "\n",
      "---- stderr ----\n",
      "sbatch: defined options\n",
      "sbatch: -------------------- --------------------\n",
      "sbatch: account             : covid19dynstat\n",
      "sbatch: array               : 1\n",
      "sbatch: dependency          : afterany:8409333\n",
      "sbatch: error               : /p/project/covid19dynstat/%u/runs/%A_e.txt\n",
      "sbatch: job-name            : 134_POST_ROUT\n",
      "sbatch: licenses            : home@just,project@just,scratch@just\n",
      "sbatch: mail-type           : BEGIN,END,FAIL,REQUEUE,STAGE_OUT\n",
      "sbatch: mail-user           : leffenberger@uos.de\n",
      "sbatch: nodes               : 1\n",
      "sbatch: ntasks-per-node     : 1\n",
      "sbatch: output              : /p/project/covid19dynstat/%u/runs/%A_o.txt\n",
      "sbatch: partition           : batch\n",
      "sbatch: time                : 08:00:00\n",
      "sbatch: verbose             : 2\n",
      "sbatch: -------------------- --------------------\n",
      "sbatch: end of defined options\n",
      "sbatch: debug:  propagating RLIMIT_CORE=0\n",
      "sbatch: debug:  propagating SLURM_PRIO_PROCESS=0\n",
      "sbatch: debug:  propagating UMASK=0022\n",
      "sbatch: debug:  Munge authentication plugin loaded\n",
      "sbatch: Cray/Aries node selection plugin loaded\n",
      "\n",
      "slurm_jobid =  8409343\n"
     ]
    }
   ],
   "source": [
    "submit_dir_post = os.path.join(source_dir, 'src')\n",
    "print(\"submit_dir_post = \", submit_dir_post)\n",
    "\n",
    "if submit_job_post:\n",
    "    \n",
    "    sbatch_addargs = '-vv'\n",
    "\n",
    "    if slurm_chain:\n",
    "        sbatchout_file_ia = os.path.join(submit_dir_ia, slurm_jobfile_ia + \".sbatchout\")\n",
    "        slurm_jobid_ia = get_slurm_jobid(sbatchout_file_ia)\n",
    "        #if slurm_jobid_ia:\n",
    "        #    sbatch_addargs += \" --dependency=aftercorr:{}\".format(slurm_jobid_ia)\n",
    "    \n",
    "    submit_job(slurm_jobfile_post, submit_dir_post, sbatch_addargs)\n",
    "    \n",
    "\n",
    "    # better wait for a few seconds to ensure slurm has processed the new job internally\n",
    "    # this ensures, that squeue will show at least some information\n",
    "    time.sleep(5)\n",
    "else:\n",
    "    print(\"NO submit of slurm job\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show status of submitted job (sample_ia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slurm_jobid =  8409343\n",
      "squeue_cmd =  ['squeue', '-l', '-u', 'effenberger2', '-j', '8409343']\n",
      "Mon Jul 20 11:03:36 2020\n",
      "             JOBID PARTITION     NAME     USER    STATE       TIME TIME_LIMI  NODES NODELIST(REASON)\n",
      "       8409343_[1]     batch 134_POST effenber  PENDING       0:00   8:00:00      1 (Dependency)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get job id\n",
    "sbatchout_file_post = os.path.join(submit_dir_post, slurm_jobfile_post + \".sbatchout\")\n",
    "slurm_jobid_post = get_slurm_jobid(sbatchout_file_post)\n",
    "\n",
    "# call 'squeue'\n",
    "if slurm_jobid_post:\n",
    "    squeue_out_post = status_job(slurm_jobid_post)\n",
    "    print(squeue_out_post)\n",
    "else:\n",
    "    print(\"ERROR: no slurm job id found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileinput.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRODUCE THE PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slurm_jobfile_post =  /p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/src/gridjob_sample_window_posterior.slurm\n",
      "slurm_shfile_ia =  /p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/src/gridjob_produce_plots_134.slurm.sh\n",
      "file_counties =  /p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/data/counties/counties.pkl\n",
      "file_iaeffect = /p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/data/ia_effect_samples/covid19_{}.pkl\n",
      "dir_mcmcsamples =  /p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/data/mcmc_samples_backup\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# check for SLURM job file\n",
    "slurm_jobfile_plots = os.path.join(source_dir, 'src', \"gridjob_produce_plots.slurm\")\n",
    "if not os.path.exists(slurm_jobfile_post):\n",
    "    print(\"ERROR: original SLURM job file does not exist\")\n",
    "    print(\"       please check for \", slurm_jobfile_post)\n",
    "    raise IpyExit\n",
    "else:\n",
    "    print(\"slurm_jobfile_post = \", slurm_jobfile_post)\n",
    "\n",
    "slurm_shfile_plots_original = os.path.join(source_dir, 'src', \"gridjob_produce_plots.slurm.sh\")\n",
    "slurm_shfile_plots = os.path.join(source_dir, 'src', \"gridjob_produce_plots_{}.slurm.sh\".format(sample_date_id))\n",
    "copyfile(slurm_shfile_plots_original, slurm_shfile_plots )\n",
    "if not os.path.exists(slurm_shfile_plots):\n",
    "    print(\"ERROR: original SLURM sh file does not exist\")\n",
    "    print(\"       please check for \", slurm_shfile_plots)\n",
    "    raise IpyExit\n",
    "print(\"slurm_shfile_ia = \", slurm_shfile_plots)\n",
    "\n",
    "    \n",
    "# check is shell-script has executable bit\n",
    "if not os.access(slurm_shfile_post, os.X_OK):\n",
    "    with open(slurm_shfile_post, \"r\") as fd:\n",
    "        os.fchmod(fd.fileno(), 0o755)\n",
    "\n",
    "if submit_job_post:\n",
    "    \n",
    "    # check required input\n",
    "    file_counties = os.path.join(source_data_dir, 'counties', 'counties.pkl')\n",
    "    if not os.path.isfile(file_counties):\n",
    "        print(\"ERROR: file data/counties.pkl is missing\")\n",
    "        raise IpyExit\n",
    "    else:\n",
    "        print(\"file_counties = \", file_counties)\n",
    "\n",
    "    if not slurm_chain:\n",
    "        # check output of sample_ia (only if we slurm dependencies)\n",
    "        dir_iaeffect = os.path.join(source_data_dir, 'ia_effect_samples')\n",
    "        for i in range(100):\n",
    "            file_iaeffect = os.path.join(dir_iaeffect, \"covid19_{}.pkl\".format(i))\n",
    "            if not os.path.isfile(file_iaeffect):\n",
    "                print(\"ERROR: file \" + file_iaeffect + \"  is missing\")\n",
    "                raise IpyExit\n",
    "        print(\"file_iaeffect = \" + dir_iaeffect + \"/covid19_{}.pkl\")\n",
    "    \n",
    "    # check output directory\n",
    "    dir_mcmcsamples = os.path.join(source_data_dir, 'mcmc_samples_backup')\n",
    "    if not os.path.exists(dir_mcmcsamples):\n",
    "        os.mkdir(dir_mcmcsamples)\n",
    "    if not os.path.isdir(dir_mcmcsamples):\n",
    "        print(\"ERROR: \" + dir_mcmcsamples + \" not a directory\")\n",
    "        raise IpyExit\n",
    "        \n",
    "    #if len(os.listdir(dir_mcmcsamples)) > 1:\n",
    "    #    print(\"ERROR: directory \" + dir_mcmcsamples + \" not empty\")\n",
    "    #    raise IpyExit\n",
    "    print(\"dir_mcmcsamples = \", dir_mcmcsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileinput.close()\n",
    "import fileinput\n",
    "\n",
    "def prepare_jobfile_plots(slurm_jobfile_plots):\n",
    "    \n",
    "    # replace lines with user-info\n",
    "    finput = fileinput.input(slurm_jobfile_plots, inplace=1)\n",
    "    try:\n",
    "        for line in finput:\n",
    "            line = \"#SBATCH --job-name={}_PLOT_ROUT\\n\".format(sample_date_id) if \"#SBATCH --job-name=\" in line else line\n",
    "            line = \"#SBATCH --dependency=afterany:{}\\n\".format(slurm_jobid_post) if \"#SBATCH --dependency\" in line else line\n",
    "            line = \"srun --exclusive -n ${{SLURM_NTASKS}} gridjob_produce_plots_{}.slurm.sh\\n\".format(sample_date_id) if \"srun\" in line else line\n",
    "            print(line, end='')\n",
    "    except:\n",
    "        print(\"ERROR: could not prepare slurm job file\")\n",
    "        raise IpyExit\n",
    "    finput.close()\n",
    "\n",
    "if submit_job_post:\n",
    "    prepare_jobfile_plots(slurm_jobfile_plots)\n",
    "else:\n",
    "    print(\"NO submit of slurm ia job\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_shfile_plots(slurm_shfile_plots):\n",
    "    \n",
    "    # replace lines with user-info\n",
    "    finput = fileinput.input(slurm_shfile_plots, inplace=1)\n",
    "    try:\n",
    "        for line in finput:\n",
    "            line = \"DAT_ID={}\\n\".format(sample_date_id) if \"DAT_ID=\" in line else line\n",
    "            print(line, end='')\n",
    "    except:\n",
    "        print(\"ERROR: could not prepare slurm job file\")\n",
    "        raise IpyExit\n",
    "    finput.close()\n",
    "\n",
    "if submit_job_ia:\n",
    "    prepare_shfile_plots(slurm_shfile_plots)\n",
    "else:\n",
    "    print(\"NO submit of slurm ia job\")\n",
    "    \n",
    "# check is shell-script has executable bit\n",
    "if not os.access(slurm_shfile_plots, os.X_OK):\n",
    "    with open(slurm_shfile_plots, \"r\") as fd:\n",
    "        os.fchmod(fd.fileno(), 0o755)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit_dir_post =  /p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/src\n",
      "submitting slurm job\n",
      "sbatch_cmd =  ['sbatch', '-vv', '/p/project/covid19dynstat/effenberger2/BSTIM-Covid19_Window_Final/src/gridjob_produce_plots.slurm']\n",
      "---- stdout ----\n",
      "Submitted batch job 8409344\n",
      "\n",
      "---- stderr ----\n",
      "sbatch: defined options\n",
      "sbatch: -------------------- --------------------\n",
      "sbatch: account             : covid19dynstat\n",
      "sbatch: array               : 1\n",
      "sbatch: dependency          : afterany:8409343\n",
      "sbatch: error               : /p/project/covid19dynstat/%u/runs/%A_e.txt\n",
      "sbatch: job-name            : 134_PLOT_ROUT\n",
      "sbatch: licenses            : home@just,project@just,scratch@just\n",
      "sbatch: mail-type           : BEGIN,END,FAIL,REQUEUE,STAGE_OUT\n",
      "sbatch: mail-user           : leffenberger@uos.de\n",
      "sbatch: nodes               : 1\n",
      "sbatch: ntasks-per-node     : 1\n",
      "sbatch: output              : /p/project/covid19dynstat/%u/runs/%A_o.txt\n",
      "sbatch: partition           : batch\n",
      "sbatch: time                : 1-00:00:00\n",
      "sbatch: verbose             : 2\n",
      "sbatch: -------------------- --------------------\n",
      "sbatch: end of defined options\n",
      "sbatch: debug:  propagating RLIMIT_CORE=0\n",
      "sbatch: debug:  propagating SLURM_PRIO_PROCESS=0\n",
      "sbatch: debug:  propagating UMASK=0022\n",
      "sbatch: debug:  Munge authentication plugin loaded\n",
      "sbatch: Cray/Aries node selection plugin loaded\n",
      "\n",
      "slurm_jobid =  8409344\n"
     ]
    }
   ],
   "source": [
    "submit_dir_post = os.path.join(source_dir, 'src')\n",
    "print(\"submit_dir_post = \", submit_dir_post)\n",
    "\n",
    "if submit_job_post:\n",
    "    \n",
    "    sbatch_addargs = '-vv'\n",
    "\n",
    "    if slurm_chain:\n",
    "        sbatchout_file_ia = os.path.join(submit_dir_ia, slurm_jobfile_ia + \".sbatchout\")\n",
    "        slurm_jobid_ia = get_slurm_jobid(sbatchout_file_ia)\n",
    "        #if slurm_jobid_ia:\n",
    "        #    sbatch_addargs += \" --dependency=aftercorr:{}\".format(slurm_jobid_ia)\n",
    "    \n",
    "    submit_job(slurm_jobfile_plots, submit_dir_post, sbatch_addargs)\n",
    "    \n",
    "\n",
    "    # better wait for a few seconds to ensure slurm has processed the new job internally\n",
    "    # this ensures, that squeue will show at least some information\n",
    "    time.sleep(5)\n",
    "else:\n",
    "    print(\"NO submit of slurm job\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid19dynstat_v01",
   "language": "python",
   "name": "covid19dynstat_v01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
